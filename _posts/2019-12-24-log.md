---
layout: post
title: "2019년 12월 24일 로그"
---

## COMPUTER VISION

### INTRODUCTION

![Figure 1.1](/assets/images/20191224/figure.1.1.png)

Figure 1.1 The human visual system has no problem interpreting the subtle variations in translucency and shading in this photograph and correctly segmenting the object from its background.

![Figure 1.2](/assets/images/20191224/figure.1.2.png)

Figure 1.2 Some examples of computer vision algorithm and applications. (a) Structure from motion algorithms can reconstruct a sparse 3D point model of a large complex scene from hundreds of partially overlapping photographs. (b) Stereo matching algorithms can build a detailed 3D model of a building facade from hundreds of differently exposed photographs taken from the Internet. (c) Person tracking algorithms can track a person walking in front of a cluttered background. (d) Face detection algorithms, coupled with color-based clothing and hair detection algorithms, can locate and recognize the individuals in this image.

### 1.1 WHAT IS COMPUTER VISION?

As human, we perceive the three dimensional structure of the world around us with apparent ease. Think of how vivid the three dimensional percept is when you look at a vase of flowers sitting on the table next to you. You can tell the shape and translucency of each petal through the subtle patterns of light and shading that play across its surface and effortlessly segment each flower from the background of the scene. Looking at a framed group portrait, you can easily count (and name) all of the people in the picture and even guess at their emotions from their facial appearance. Perceptual psychologists have spent decades trying to understand how the visual system works and, even though they can devise optical illusions to tease apart some of its principles, a complete solution to this puzzle remains elusive.

Researchers in computer vision have been developing, in parallel, mathematical techniques for recovering the three dimensional shape and appearance of objects in imagery. We now have reliable techniques for accurately computing a partial 3D model of an environment from thousands of partially overlapping photographs. Given a large enough set of views of a particular object of facade, we can create accurate dense 3D surface models using stereo matching. We can track a person moving against a complex background. We can even, with moderate success, attempt to find and name all of the people in a photograph using a combination of face, clothing, and hair detection and recognition. However, despite all of these advances, the dream of having a computer interpret an image at the same level as a two year old (for example, counting all of the animals in a picture) remain elusive. Why is vision so difficult? In part, it is because vision is an inverse problem, in which we seek to recover some unknowns given insufficient information to fully specify the solution. We must therefore resort to physics based and probabilistic models to disambiguate between potential solutions. However, modeling the visual world in all of its rich complexity is far more difficult than, say, modeling the vocal tract that produces spoken sounds.

The forward models that we use in computer vision are usually developed in physics (radiometry, optics, and sensor design) and in computer graphics. Both of these fields model how objects move and animate, how light reflects off their surfaces, is scattered by the atmosphere, refracted through camera lenses (or human eyes), and finally projected onto a flat (or curved) image plane. While computer graphics are not yet perfect (no fully computer animated movie with human characters has yet succeeded at crossing the uncanny valley that separates real humans from android robots and computer animated humans), in limited domain, such as rendering a still scene composed of everyday objects or animating extinct creatures such as dinosaurs, the illusion of reality is perfect.

Figure 1.3 Some common optical illusions and what they might tell us about the visual system: (a) The classic Muller-Lyer illusion, where the length of the two horizontal lines appear different, probably due to the imagined perspective effects. (b) The "white" square B in the shadow and the "black" square A in the light actually have the same absolute intensity value. The percept is due to brightness constancy, the visual system's attempt to discount illumination when interpreting colors. Image courtesy of Ted Adelson, http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html (c) A variation of the Hermann grid illusion, courtesy of Hany Farid, http://www.cs.dartmouth.edu/~farid/illusions/hermann.html As you move your eyes over the figure, gray spots appear at the intersections. (d) Count the red Xs in the left half of the figure. Now count them in the right half. Is significantly harder? The explanation has to do with a pop out effect, which tells us about the operations of parallel perception and integration pathways in the brain.

In computer vision, we are trying to do the inverse, i.e., to describe the world that we see in one or more images and to reconstruct its properties, such as shape, illumination, and color distributions. It is amazing that humans and animals do this so effortlessly, while computer vision algorithms are so error prone. People who have not worked in the field often under-estimate the difficulty of the problem. (Colleagues at work often ask me for software to find name all people in photos, so they can get on with the more "interesting" work.) This misperception that vision should be easy dates back to the early days of artificial intelligence, when it was initially believed that the cognitive (logic proving and planning) parts of intelligence were intrinsically more difficult than the perceptual components.

The good news is that computer vision is being used today in a wide variety of real world applications, which include:

- Optical character recognition (OCR): reading handwritten postal codes on letters and automatic number plate recognition
- Machine inspection: rapid parts inspection for quality assurance using stereo vision with specialized illumination to measure tolerances on aircraft wings or auto body parts or looking for defects in steel casting using X-ray vision
- Retail: object recognition for automated checkout lanes
- 3D modeling building (photogrammetry): fully automated construction of 3D models from aerial photographs used in systems such as Bing Maps
- Medical imaging: registering pre-operative and intra-operative imagery or performing long-term studies of people;s brain morphology as they age
- Automotive safety: detecting unexpected obstacles such as pedestrians on the street, under conditions where active vision techinques such as radar or lidar do not work well.
- Match move: merging computer-generated imagery (CGI) with live action footage by tracking feature points in the source video to estimate the 3D camera motion and shape of the environment. Such techniques are widely used in Hollywood; they also require the use of precise matting to insert new elements between foreground and background elements.

- Motion capture (mocap): using retro-reflective markers viewed from multiple cameras or other vision-based techniques to capture actors for computer animation
- Surveillance: monitoring for intruders, analyzing highway traffic, and monitoring pools for drowning victims
- Fingerprint recognition and biometrics: for a automatic access authentication as well as forensic applictions.

David Lowe's Web site of industrial vision application (http://www.cs.ubc.ca/spider/lowe/vision.html) lists many other interesting industrial applications of computer vision. While the above applications are all extremely important, they mostly pertain to fairly specialized kinds of imagery and narrow domains.

In this book, we focus more on broader consumer-level applications, such as fun things you can do with your own personal photographs and video. These include:

- Stitching: turning overlapping photos into a single seamlessly stitched panorama
- Exposure bracketing: merging multiple exposures taken under challenging lighting conditions into a single perfectly exposed image
- Morphing: turning a picture of one of your friends into another, using a seamless morph transition
- 3D modeling: converting one or more snapshots into a 3D model of the object or person you are photographing
- Video match move and stabilization: insert 2D pictures or 3D models into your videos by automatically tracking nearby reference points or using motion estimates to remove shake from your videos.
- Photo-based walkthroughs: navigating a large collection of photographs, such as the interior of your house, by flying between different photos in 3D
- Face detection: for improved camera focusing as well as more relevant image searching
- Visual authentication: automatically logging family members onto your home computer as they sit down in front of the webcam

> continue

## 컴퓨터 비전

### 소개

인간은 주변 세계의 3차원 구조를 명백하고 쉽게 인식합니다. 당신이 당신 옆에 있는 테이블에 놓여 있는 꽃병의 꽃을 볼 때 3차원으로 인식하는 것이 얼마나 생생한지 생각해보세요. 표면을 가로질러 재생되는 미묘한 빛과 음영의 패턴을 통해 각 꽃 잎의 모양과 반투명도를 쉽게 말할 수 있으며 어떤 장면의 배경에서 각 꽃을 쉽게 분류할 수 있습니다. 액자의 초상화를 보면 사진 속의 모든 사람들의 수를 쉽게 세고 이름을 짓고 얼굴 모양에서 감정을 추측할 수도 있습니다. 지각 심리학자들은 시각 시스템의 작동 방식을 이해하기 위해 수십 년을 보냈지만, 비록 그 원리의 일부를 알수는 있었지만 이 퍼즐에 대한 완전한 해결책은 찾기 힘들었습니다.

컴퓨터 비전 연구자들은 이미지에서 물체의 3차원 모델을 추출하기 위한 수학적 기법을 개발해 왔습니다. 이제 수천 개의 사진에서 특정 환경의 부분 3D 모델을 정확하게 계산할 수 있는 기술이 있습니다. 특정 파사드 객체에 대한 충분한 뷰 세트가 주어지면 스테레오 매칭을 사용하여 정확한 고밀도 3D 표면 모델을 만들 수 있습니다. 복잡한 배경에서 움직이는 사람을 추적할 수도 있습니다. 얼굴, 의복, 머리카락 감지 및 인식을 조합하여 사진에서 모든 사람을 찾고 이름을 지정할 수도 있습니다. 그러나 이러한 모든 발전에도 불구하고 컴퓨터가 2살짜리와 같은 수준에서 이미지를 해석하도록하는 꿈은 여전히 애매모호합니다. (그림에서 있는 모든 동물을 세는 것) 비전이 왜 그렇게 어려운가? 부분적으로 비전이 역의 문제이기 때문에 솔수션을 완전히 지정하기에 정보가 충분하지 않은 미지의 일부를 복구해야 하기 때문입니다. 그러므로 우리는 잠재적인 해결책을 명확하게 하기 위해 물리학 및 확률론적 모델에 의지해야 합니다. 그러나 풍부한 복잡성으로 시각적 세계를 모델링하는 것은 말하기 소리를 생성하는 보컬을 모델링하는 것보다 휠씬 어렵습니다.

우리가 컴퓨터 비전에 사용하는 포워드 모델은 일반적으로 물리학(방사선, 광학 및 센서 설계) 및 컴퓨터 그래픽으로 개발합니다. 이 두 분야는 물체가 어떻게 움직이고, 어떻게 빛이 표면에서 반사되는지, 대기에 산란됙, 카메라 렌즈 또는 사람의 눈을 통해 굴절되고, 최정적으로 평면 혹은 곡선 이미지가 투영되는지를 설명합니다. 컴퓨터 그래픽은 아직 완벽하지는 않지만 제한된 영역에서 공룡과 같은 사물이나 멸종 생물을 애니메이션으로 만들어냅니다.

컴퓨터 비전에서는 하나 이상의 이미지에서 보는 세계를 묘사하고 모양, 조명 및 색상 분포와 같은 속성을 재구성하기 위해 노력을 기울이고 있습니다. 컴퓨터 비전 알고리즘은 오류가 발생하기 쉬운 반면 사람과 동물이 그것으 쉽게 할 수 있다는 것은 놀라운 일입니다. 현장에서 일하지 않은 사람들은 종종 문제의 어려움을 과소 평가합니다. 처음에는 지능인지적 부분이 지각적 요소보다 본질적으로 더 어렵다고 믿었습니다.

좋은 소식은 오늘날 컴퓨터 비전이 다음과 같은 다양한 실제 응용 프로그램에서 사용되고 있다는 것입니다.

- 광학문자인식(OCR): 문자로 작성된 우편 번호 일기 및 자동차 번호퐌 인식
- 기계검사: 항공기 날개나 자동차 본체 부품의 공차를 측정하거나 X-ray 비전을 사용하여 철강 주조의 결함을 찾기 위해 특수 조명이 있는 스테레오 비전을 사용하여 품질을 보증하기 위한 신속한 부품 검사
- 소매점: 자동 결제 레인을 위한 객체 인식
- 3D 모델링 빌딩(사진 측량): Bing Maps 와 같은 시스템에 사용되는 항공 사진에서 3D 모델의 완전 자동화된 구성
- 의료영상: 수술 전 혹은 수술 중 이미지를 등록하거나 사람들에 대한 장기 연구 수행, 나이에 따른 뇌형태
- 자동차 안전: 레이더 혹은 라이더와 같은 능동 비전 기술이 제대로 작동하지 않는 상황에서 거리의 보행자와 같은 예기치 않은 장애물을 감지
- 매치이동: 소스 비디오의 특징점을 추적하여 컴퓨터 생성 이미지(CGI) 를 라이브 액션 푸티지와 병합하여 3D 카메로 모션 및 환경 모양을 추정합니다. 이러한 기술은 할리우드에서 널리 사용됩니다. 또한 전경과 배경 요소 사이에 새 요소를 삽입하려면 정확한 매트를 사용해야 합니다.
- 모션 캡쳐: 여러 카메로 또는 다른 비전 기반 기술에서 본 역반사 마커를 사용하여 컴퓨터 애니테이션을 위한 액터 캡쳐
- 감시: 칩입자 모니터링, 고속도로 교통 분석 및 익사 피해주 풀 모니터링
- 지문인식 및 생체인식: 법의학 적용뿐만 아니라 자동 액세스 인증

이 책에서는 개인 사진과 비디오로 할 수 있는 재미있는 일과 같은 광범위한 소비자 수준의 응용프로그램에 중점을 두었습니다. 여기에는 다음이 포함됩니다.

- 스티칭: 겹치는 사진을 완벽하게 스티칭된 단일 파노라마로 전환
- 노출 브라케팅: 까다로운 조명 조건에서 여러 노출을 하나의 완벽하게 노출된 이미지로 변환
- 모핑: 원할한 모프 전환을 사용하여 친구의 사진을 다른 친구로 전환
- 3D 모델링: 하나 이상의 스냅 샷을 촬영중인 객체 또는 사람의 3D 모델로 변환
- 비디오 일치 이동 및 안정화: 근처의 기분점을 자동으로 추적하거나 움직임을 추정하여 비디오에서 흔들림을 제거하여 2D 사진 또는 3D 모델을 비디오에 삽입합니다
- 사진 기반 연습: 3D 로 서로 다른 사진 사이에 비행하는 집 내부와 같은 다양한 사진 모음 탐색
- 얼굴인식: 카메라 초점을 개선하고 관련성 높은 이미지 검색
- 시각적 인증: 가족 구성원이 웹캠 앞에 앉아 홈 컴퓨터에 자동으로 로그인
