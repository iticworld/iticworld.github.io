---
layout: post
title: "2020년 1월 14일 개발로그"
---

<a name="opencv"></a>
# OPENCV

## SMOOTHING IMAGES

In this tutorial you will learn how to apply diverse linear filters to smooth images using OpenCV functions such as:

- blur
- GaussianBlur
- medianBlur
- bilateralFilter

### THEORY

Smoothing, also called blurring, is a simple are frequently used image processing operation.
There are many reasons for smoothing. In this tutorial we will focus on smoothing in order to reduce noise (other uses will be seen in the following tutorial). To perform a smoothing operation we will apply a filter to our image. The most common type of filter are linear, in which an output pixel's value is determined as a weighted sum of input pixel values:

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <msub>
    <mi>f</mi>
    <mtext>out</mtext>
   </msub>
   <mrow>
    <mrow>
     <mo fence="true" stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mi>i</mi>
       <mi>,</mi>
       <mi>j</mi>
      </mrow>
     </mrow>
     <mo fence="true" stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">=</mo>
    <mrow>
     <munderover>
      <mo stretchy="false">∑</mo>
      <mrow>
       <mi>x</mi>
       <mo stretchy="false">=</mo>
       <msub>
        <mi>x</mi>
        <mtext>min</mtext>
       </msub>
      </mrow>
      <msub>
       <mi>x</mi>
       <mtext>max</mtext>
      </msub>
     </munderover>
     <mrow>
      <munderover>
       <mo stretchy="false">∑</mo>
       <mrow>
        <mi>y</mi>
        <mo stretchy="false">=</mo>
        <msub>
         <mi>y</mi>
         <mtext>min</mtext>
        </msub>
       </mrow>
       <msub>
        <mi>y</mi>
        <mtext>max</mtext>
       </msub>
      </munderover>
      <mrow>
       <msub>
        <mi>f</mi>
        <mtext>in</mtext>
       </msub>
       <mrow>
        <mo fence="true" stretchy="false">(</mo>
        <mrow>
         <mrow>
          <mrow>
           <mi>i</mi>
           <mo stretchy="false">+</mo>
           <mi>x</mi>
          </mrow>
          <mi>,</mi>
          <mrow>
           <mi>j</mi>
           <mo stretchy="false">+</mo>
           <mi>y</mi>
          </mrow>
         </mrow>
        </mrow>
        <mo fence="true" stretchy="false">)</mo>
       </mrow>
       <msub>
        <mi>f</mi>
        <mtext>filter</mtext>
       </msub>
       <mrow>
        <mo fence="true" stretchy="false">(</mo>
        <mrow>
         <mrow>
          <mi>x</mi>
          <mi>,</mi>
          <mi>y</mi>
         </mrow>
        </mrow>
        <mo fence="true" stretchy="false">)</mo>
       </mrow>
      </mrow>
     </mrow>
    </mrow>
   </mrow>
  </mrow>
 </semantics>
</math>

The function <math><semantics><mrow><msub><mi>f</mi><mtext>filter</mtext></msub><mrow><mo fence="true" stretchy="false">(</mo><mrow><mrow><mi>x</mi><mi>,</mi><mi>y</mi></mrow></mrow><mo fence="true" stretchy="false">)</mo></mrow></mrow></semantics></math> is called the kernel, which is nothing more than the coefficients of the filter. It helps to visualize a filter as a window of coefficients sliding across the image. There are many kind of filters, here we will mention the most used:

__NORMALIZED BOX FILTER__

This filter is the simplest of all! Each output pixel is the mean of its kernel neighbors (all of them contribute with equal weights).

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>f</mi>
     <mtext>noralized box filter</mtext>
    </msub>
    <mo stretchy="false">=</mo>
    <mfrac>
     <mn>1</mn>
     <mrow>
      <mi mathvariant="italic">width</mi>
      <mo stretchy="false">×</mo>
      <mi mathvariant="italic">height</mi>
     </mrow>
    </mfrac>
   </mrow>
   <mrow>
    <mo fence="true" stretchy="true">[</mo>
    <mrow>
     <mtable>
      <mtr>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mo stretchy="false">⋯</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mo stretchy="false">⋯</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mo stretchy="false">⋮</mo>
       </mtd>
       <mtd>
        <mo stretchy="false">⋮</mo>
       </mtd>
       <mtd>
        <mo stretchy="false">⋮</mo>
       </mtd>
       <mtd>
        <mo stretchy="false">⋱</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mo stretchy="false">⋯</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
     </mtable>
    </mrow>
    <mo fence="true" stretchy="true">]</mo>
   </mrow>
  </mrow>
 </semantics>
</math>

__GAUSSIAN FILTER__

Probably the most useful filter (although not the fastest). Gaussian filtering is done by convolving each point in the input array with a Gaussian kernel and then summing them all to produce the output array. Just to make the picture clearer, remember how a one-dimensional gaussian kernel look like?

![image](/assets/images/Smoothing_Tutorial_theory_gaussian_0.jpg)

> TODO: DRAW GAUSSIAN GRAPH

Assuming that an image is one-dimension, you can notice that the pixel located in the middle would have the biggest weight. The weight of its neighbors decreases as the spatial distance between them and the center pixel increase.

Remember that a two-dimensional gaussian can be represented as:

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <msub>
    <mi>f</mi>
    <mtext>gaussian</mtext>
   </msub>
   <mrow>
    <mrow>
     <mo fence="true" stretchy="false">(</mo>
     <mrow>
      <mrow>
       <mi>x</mi>
       <mi>,</mi>
       <mi>y</mi>
      </mrow>
     </mrow>
     <mo fence="true" stretchy="false">)</mo>
    </mrow>
    <mo stretchy="false">=</mo>
    <mi>A</mi>
   </mrow>
   <msup>
    <mi>e</mi>
    <mrow>
     <mfrac>
      <mrow>
       <mo stretchy="false">−</mo>
       <msup>
        <mrow>
         <mo fence="true" stretchy="false">(</mo>
         <mrow>
          <mrow>
           <mi>x</mi>
           <mo stretchy="false">−</mo>
           <msub>
            <mi>μ</mi>
            <mi>x</mi>
           </msub>
          </mrow>
         </mrow>
         <mo fence="true" stretchy="false">)</mo>
        </mrow>
        <mn>2</mn>
       </msup>
      </mrow>
      <mrow>
       <mn>2</mn>
       <msup>
        <msub>
         <mi>σ</mi>
         <mi>x</mi>
        </msub>
        <mn>2</mn>
       </msup>
      </mrow>
     </mfrac>
     <mo stretchy="false">+</mo>
     <mfrac>
      <mrow>
       <mo stretchy="false">−</mo>
       <msup>
        <mrow>
         <mo fence="true" stretchy="false">(</mo>
         <mrow>
          <mrow>
           <mi>x</mi>
           <mo stretchy="false">−</mo>
           <msub>
            <mi>μ</mi>
            <mi>y</mi>
           </msub>
          </mrow>
         </mrow>
         <mo fence="true" stretchy="false">)</mo>
        </mrow>
        <mn>2</mn>
       </msup>
      </mrow>
      <mrow>
       <mn>2</mn>
       <msup>
        <msub>
         <mi>σ</mi>
         <mi>y</mi>
        </msub>
        <mn>2</mn>
       </msup>
      </mrow>
     </mfrac>
    </mrow>
   </msup>
  </mrow>
 </semantics>
</math>

where <math><semantics><mi>μ</mi></semantics></math> is the mean (the peak) and <math><semantics><msup><mi>σ</mi><mn>2</mn></msup></semantics></math> represents the variance (per each of the variables x and y).

__MEDIAN FILTER__

The median filter run through each element of the signal (in this case the image) and replace each pixel with the median of its neighboring pixels (located in a square neighborhood arourd the evaluated pixel).

__BILATERAL FILTER__

So far, we have explained some filters which main goal is to smooth an input image. However, sometimes the filters do not only dissolve the noise, but also smooth away the edges. To avoid this (at certain extent at least), we can use a bilateral filter. In an analogous way as the Gaussian filter, the bilateral filter also considers the neighboring pixels with weights assigned to each of them. These weights have two components, the first of which is the same weighting used by the Gaussian filter. The second component takes into account the difference in intensity between the neighboring pixels and the evaluated one. For a more detailed explanation you can check [this link](http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html).

```
cv::blur(source: array, destination: array, size: size, anchor: point = point(-1, -1), border: int = BORDER_DEFAULT)
```

Blurs an image using the normalized box filter. The function smooths an image using the kernel:

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mrow>
    <msub>
     <mi>f</mi>
     <mtext>noralized box filter</mtext>
    </msub>
    <mo stretchy="false">=</mo>
    <mfrac>
     <mn>1</mn>
     <mrow>
      <mi mathvariant="italic">width</mi>
      <mo stretchy="false">×</mo>
      <mi mathvariant="italic">height</mi>
     </mrow>
    </mfrac>
   </mrow>
   <mrow>
    <mo fence="true" stretchy="true">[</mo>
    <mrow>
     <mtable>
      <mtr>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mo stretchy="false">⋯</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mo stretchy="false">⋯</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mo stretchy="false">⋮</mo>
       </mtd>
       <mtd>
        <mo stretchy="false">⋮</mo>
       </mtd>
       <mtd>
        <mo stretchy="false">⋮</mo>
       </mtd>
       <mtd>
        <mo stretchy="false">⋱</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mo stretchy="false">⋯</mo>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
      </mtr>
     </mtable>
    </mrow>
    <mo fence="true" stretchy="true">]</mo>
   </mrow>
  </mrow>
 </semantics>
</math>

The call `blur(source, destination, size, anchor, border)` is equivalent to `boxFilter(source, destination, source.type(), anchor, true, border)`

| source | input image; it can have any number of channels, which are processed independently, but the depth should be `CV_8U`, `CV_16U`, `CV_16S`, `CV_32F` or `CV_64F` |
| destination | output image of the same size and type as source. |
| size | blurring kernel size |
| anchor | anchor point; default value `point(-1, -1)` means that the anchor is at the kerenel center. |
| border | border mode used to extrapolate pixels outside of the image, see BorderType. |

> https://docs.opencv.org/4.2.0/dc/dd3/tutorial_gausian_median_blur_bilateral_filter.html


# GEOMETRIC OBJECTS AND TRANSFORMATIONS

We are now ready to concentrate on three-dimensional graphics. Much of this chapter is concerned with such matters as how to represent basic geometric types, how to convert between various representations, and what statements we can make about geometric objects independent of a particular representation.

We begin with an examination of the mathematical underpinnings of computer graphics. This approach among a geometric entity, its representation in a particular reference system, and a mathematical abstraction of it.

We use the notions of affine and euclidean vector spaces to create the necessary mathematical foundation for later work. One of our goals is to establish a method for dealing with geometric problems that is independent of coordinate systems. The advantages of such an approach will be clear when we worry about how to represent the geometric objects with which we would like to work. The coordinate-free apprach will prove to be far more robust than one based on representing the objects in a particular coordinate system or frame. This coordinate-free approach also leads to the use of homogeneous coordinates, a system that not only enables use to explain this approach but also leads to efficient implementation techniques.

We use the terminology of abstract data types to reinforce the distinction between an object and its representation. Our development will show that the mathematics arise naturally from our desire to manipulate a few basic geometric objects. Much of what we present here is an application of vector spaces, geometry, and linear algebra. Appendices B and C summarize the formalities of vector spaces and matrix algebra, respectively.

In a vein similar to the approach we took in Chapter 2, we develop a simple application program to illustrate the basic principles and to see how the concepts are realized within an API. In this chapter, our example is focused on the representation and transformations of a cube. We also consider how to specify transformations interactively and apply them smoothly. Because transformations are key to both modeling and implementation, we will develop transformation capabilities that can be carried out in both the application code and in the shaders.


## 3.1. SCALARS, POINTS, AND VECTORS

In computer graphics, we work with sets of geometric objects, such as lines, polygons, and polyhedra. Such objects exist in a three-dimensional world and have properties that can be described using concepts such as length and angles. As wee discovered working in two dimensions, we can define most geometric objects using a limited set of simple entities. These basic geometric objects and the relationships among them can be described using three fundamental types: scalars, points, and vectors.

Although we will consider each type from a geometric perspective, each of these types also can be defined formally, as in Appendix B, as obeying a set of axioms. Although ultimately we will use the geometric instantiation of each type, we want to take great care in distinguishing between the abstract definition of each entity and any particular example, or implementation, of it. By taking care here, we can avoid many subtle pitfalls later. Although we will work in three-dimensional spaces, virtually all our results will hold in n-dimensional spaces.

### 3.1.1. GEOMETRIC OBJECTS

Our fundamental geometric object is a point. In a three-dimensional geometric system, a point is a location in space. The only property that a point possesses is that point's location; a mathematical point has neither a size nor a shape.

Points are useful in specifying geometric objects but are not sufficient by themselves. We need real numbers to specify quantities such as the distance between two points. Real numbers - and complex numbers, which we will use occasionally - are examples of scalars. Scalars are objects that obey a set of rules that are abstractions of the operations of ordinary arithmetic. Thus, addition and multiplication and defined and obey the usual rules such as commutivity and associativity. Every scalar has multiplicative and additive inverses, which implicitly define subtraction and division.

We need one additional type - the vector - to allow use to work with directions. Physicists and mathematicians use the term vector for any quantity with direction and magnitude. Physical quantities, such as velocity and force, are vectors. A vector does not, however, have a fixed location in space.

In computer graphics, we often connect points with directed line segments, as show in Figure 3.1.





> AFFINE VECTOR SPACE, EUCLIDEAN VECTOR SPACE, HOMOGENEOUS COORDINATES
