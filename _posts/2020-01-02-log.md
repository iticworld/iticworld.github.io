---
layout: post
title: "2020년 01월 02일 개발로그"
---

TOMORROW

- https://docs.opencv.org/4.2.0/dd/d4d/tutorial_js_image_arithmetics.html

<!--

[OPENCV - TUTORIAL - GETTING STARTED WITH VIDEOS](#opencv-getting-started-with-videos)<br />
[OPENCVJS - SIMPLE VIDEO](#iticworld-getting-started-with-video)<br />
[OPENCV - ADD TRACKBAR TO YOUR APPLICATION](#add-trackbar-to-your-application)<br />
[OPENCVJS - SIMPLE TRACKBAR](#iticworld-add-trackbar-to-your-application)<br />
[OPENCV - BASIC OPERATIONS ON IMAGES](#opencv-basic-operations-on-images)<br />

<a name="opencv-basic-operations-on-images"></a>

## BASIC OPERATIONS ON IMAGES

### ACCESSING IMAGE PROPERTIES

Image properties include number of rows, columns and size, depth, channels, type of image data.

> source.type() is very important while debugging because a large number o errors in OpenCV.js code are caused by invalid data type.

<img id="opencv-20200102-input" src="/assets/images/first.jpg">

<script>
  function opencv_image_properties(o) {
    return {
      width: o.cols,
      height: o.rows,
      size: `${o.size().width} * ${o.size().height}`,
      depth: o.depth(),
      channels: o.channels(),
      type: o.type()
    };
  }
  function opencv_image_properties_run() {
    dispatch(() => {
      let o = cv.imread('opencv-20200102-input');
      console.log(opencv_image_properties(o));
      o.delete();
    });
  }
  opencv_image_properties_run();
</script>

```
let source = cv.image("input");
console.log({
              width: source.cols,
              height: source.rows,
              size: `${source.size().width} * ${source.size().height}`,
              depth: source.depth(),
              channels: source.channels(),
              type: source.type()});
```

### HOW TO CONSTRUCT MAT

There are 4 basic constructors:

```
// 1. default constructor
let mat = new cv.Mat();
// 2. two dimensional arrays by size and type
let mat = new cv.Mat(size, type);
// 3. two dimensional arrays by rows, cols, and type
let mat = new cv.Mat(rows, cols, type);
// 4. two dimensional arrays by rows, cols, and type with initialization value
let ma = new cv.Mat(rows, cols, type, new cv.Scalar());
```

There are 3 static functions:

```
// 1. Create a max which is full or zeros
let max = cv.Mat.zeros(rows, cols, type);
// 2. Create a mat which is full of ones
let max = cv.Mat.ones(rows, cols, type);
// 3. Create a mat which is an identity matrix
let mat = cv.Mat.eye(rows, cols, type);
```

There are 2 factory functions

```
// 1. Use JS array to construct a max
// For example, let mat = cv.matFromArray(2, 2, cv.CV_8UC1, [1, 2, 3, 4]);
let mat = cv.matFromArray(rows, cols, type, array);
// 2. USe imgData to constructo a max
let context = canvas.getContext('2d');
let imgData = ctx.getimageData(0, 0, canvas.width, canvas.height);
let max = cv.matFromImageDtat(imgData);
```

> Don't forget to delete cv.Mat when you don't want to use it any more.

### HOW TO COPY MAT

There are 2 ways to copy a Mat:

```
// 1. clone
let destination = source.clone();
// 2. CopyTo(only entries indicated in the mask are copied)
source.copyTo(destination, mask);
```

### HOW TO CONVERT THE TYPE OF MAT

We use the function convertTo(m, rtype, alpha=1, beta = 0)

```
convertTo(m, rtype, alpha = 1, beta = 0)
```

| m | output matrix; if it does not hav a proper size or type before the operation, it is reallocated |
| rtype | desired output matrix type or, rather, the depth since the number of channels are the same as the input has; if rtype is negative, the output matrix will have the same type as the input. |
| alpha | optional scale factor. |
| beta | optional delta added to the scaled values |

```
src.convertTo(destination, rtype);
```

### HOW USE MatVector

```
let mat = new cv.Mat();
// initialize a MatVector
let vec = new cv.MatVector();
// push a Mat back into MatVector
vec.push_back(mat);
// let cnt = vec.get(0)
mat.delete();
vec.delete();
cnt.delete;
```

> Don't forget to delete cv.Mat, cv.MatVector and cnt(the Mat you get from MatVector) when you don't want to use them any more.

### ACCESSING AND MODIFYING PIXEL VALUES

Firstly, you should know the following type relationship:

| DATA PROPERTIES | C++ TYPE | JAVASCRIPT TYPED ARRAY | MAT TYPE |
| --------------- | -------- | ---------------------- | -------- |
| data            | uchar    | Uint8Array             | CV_8U    |
| data8S          | char     | Int8Array              | CV_8S    |
| data16U         | ushort   | Uint16Array            | CV_16U   |
| data16S         | short    | Int16Array             | CV_16S   |
| data32S         | int      | Int32Array             | CV_32S   |
| data32F         | float    | Float32Array           | CV_32F   |
| data64F         | double   | Float64Array           | CV_64F   |

1. data

```
let row = 3;
let col = 4;
let source = cv.imread('input');
if(source.isContinous) {
  let R = source.data[row * source.cols * source.channels() + col * source.channels()];
  let G = source.data[row * source.cols * source.channels() + col * source.channels() + 1];
  let B = source.data[row * source.cols * source.channels() + col * source.channels() + 2];
  let A = source.data[row * source.cols * source.channels() + col * source.channels() + 3];
}
```

> Data manipulation is only valid for continuous Mat. You should use isContinuous() to check first.

2. at

| MAT TYPE | AT MANIPULATION |
| -------- | --------------- |
| CV_8U    | ucharAt         |
| CV_8S    | charAt          |
| CV_16U   | ushortAt        |
| CV_16S   | shortAt         |
| CV_32S   | intAt           |
| CV_32F   | floatAt         |
| CV_64F   | doubleAt        |

```
let row = 3;
let col = 4;
let R = source.ucharAt(row, col * source.channels());
let G = source.ucharAt(row, col * source.channels() + 1);
let B = source.ucharAt(row, col * source.channels() + 2);
let A = source.ucharAt(row, col * source.channels() + 3);
```

> At manipulation is only for single channel access and the value can't be modified.

3. ptr

| MAT TYPE | PTR MANIPULATION | JAVASCRIPT TYPED ARRAY |
| -------- | ---------------- | ---------------------- |
| CV_8U    | ucharPtr         | Uint8Array             |
| CV_8S    | charPtr          | Int8Array              |
| CV_16U   | ushortPtr        | Uint16Array            |
| CV_16S   | shortPtr         | Int16Array             |
| CV_32S   | IntPtr           | Int32Array             |
| CV_32F   | floatPtr         | Float32Array           |
| CV_64F   | doublePtr        | Float64Array           |

```
let row = 3;
let col = 4;
let source = cv.imread('input');
let pixel = source.ucharPtr(row, col);
let R = pixel[0];
let G = pixel[1];
let B = pixel[2];
let A = pixel[3];
```

mat.ucharPtr(k) get the k the row of the mat. mat.ucharPtr(i, j) get the i th row and the j the column of the mat.

### IMAGE ROI

Sometimes, you will have to play with certain region of images. For eys detection in images, first face detection is done all over the image when face is obtained, we select the face region alone and search for eyes inside it instead of searching whole image. It improves accuracy (because eyes are always on faces) and performacne (because we seearch for a small area).

We use the function: roi(rect)

```
roi(rect: Rect)
```

| rect | rectangle Region of interest. |

```
let source = cv.imread('input');
let destination = new cv.Mat();
// you can try more different parameters
let rect = new cv.Rect(100, 100, 200, 200);
destination = source.roi(rect);
cv.imshow('output'), destination);
source.delete();
destination.delete();
```

### SPLITTING AND MERGING IMAGE CHANNELS

Sometimes you will need to work separately on R, G, B channels of image. Then you need to split the RGB images to single planes. Or another time, you may need to join these individual channels to RGB image.

```
let source = cv.imread('input');
let rgbaPlanes = new cv.MatVector();
// split the mat
cv.split(Source, rgbaPlanes);
// Get R Channel
let R- rgbaPalnes.get(0);
// Merget all channels
cv.merge(rgbaPlanes, source);
source.delete();
rgbaPlanes.delete();
R.delete();
```

### MAKING BORDERS FOR IMAGES (PADDING)

If you want to create a border around the image, sometimes like a photo frame, you can cv.copyMakeBorder() function. But it has more applications for convolution operation, zero padding etc. This function take follows arguments:

```
cv.copyMakeBorder()
```

| src | input image |
| top, bottom, left, right | border width in number of pixels in corresponding directions |
| borderType | flag defining what kind of border to be added. It can be following types: |
| value | color of border if border type is cv.BORDER_CONSTANT |

- cv.BORDER_CONSTANT - Adds a constant colored border. The value sholud be given as next argument.
  - cv.BORDER_REFLECT - Border will be mirror reflection of the border elements, like this fedcba|abcdefgh|hgfedcb
  - CV_BORDER_REFLECT_101 or CV.BORDER_DEFAULT - Same as above, but with a slight change, liek this gfedcb|abcdefgh|gfedcba
  - CV.BORDER_REPLICATE - Last element is replicated throughout, loie this: aaaaaa|abcdefgh|hhhhhhh
  - cv.BORDER_WRAP - Can't explain, it will look like this: cdefgh|abcdefgh|abcdefg

```
let source = cv.imread('input');
let destiation = new cv.Mat();
// you can try more different parameters
let s = new cv.Scalar(255, 0, 0, 255);
cv.copyMakeBorder(source, destination, 10, 10, 10, 10, cv.BORDER_CONSTANT, s);
cv.imshow('input', destination);
souce.delete();
destination.delete();
```
----

-->

<a name="iticworld-add-trackbar-to-your-application"></a>

## SIMPLE TRACKBAR FOR OPENCV JS

두 이미지의 크기가 같아야 한다. 그렇지 않을 경우 예기치 못한 예외가 발생한다.
태그에서 가져온 값이 문자열이기 때문에 더하면 문자열의 더하기가 되기 때문에 정확한 계산이 힘들다.

<img id="first" width="210" height="320" src="/assets/images/first.jpg">
<img id="second" width="210" height="320" src="/assets/images/second.jpg">

0 <input id="trackbar" type="range" value="50" min="0" max="100" step="1"> 100

<script>
function simple_trackbar_decrease() {
  let trackbar = document.getElementById('trackbar');
  console.log(trackbar.value);
  if(trackbar.value < 100){
    trackbar.value = parseInt(trackbar.value) + 1;
    simple_trackbar_draw();
    setTimeout(simple_trackbar_decrease, 50);
  }
}
function simple_trackbar_run(){
  let trackbar = document.getElementById('trackbar');
  trackbar.value = 0;
  setTimeout(() => {
    if(trackbar.value < 100){
      trackbar.value = parseInt(trackbar.value) + 1;
      simple_trackbar_draw();
      setTimeout(simple_trackbar_decrease, 50);
    }
  }, 0.1);
}
</script>

<button onclick="dispatch(simple_trackbar_run)">RUN</button>


__OUTPUT__

<canvas id="output2"></canvas>

<script type="text/javascript">
  let first = document.getElementById('first');
  let second = document.getElementById('second');
  let canvas = document.getElementById('output');
  let width = first.clientWidth;
  let height = first.clientHeight;
  function simple_trackbar_draw() {
    try {
      let trackbar = document.getElementById('trackbar');
      let alpha = trackbar.value / trackbar.max;
      let beta = (1.0 - alpha);
      let sources = [ cv.imread('first'), cv.imread('second') ];
      let destination = new cv.Mat();
      cv.addWeighted(sources[0], alpha, sources[1], beta, 0.0, destination, -1);
      cv.imshow('output2', destination);
      destination.delete();
      sources[0].delete();
      sources[1].delete();
    } catch(e) {
      console.error(e);
    }
  }
</script>

----

<!--
<a name="add-trackbar-to-your-application"></a>

## ADD A TRACKBAR TO YOUR APPLICATION

### GOAL

Use HTML DOM Input Range Object to add a trackbar to your application.

### CODE DEMO

Here, we will create a simple application that blends two images.
We will let the user enter the weight by using the trackbar.

First, we need to create three canvas elements: two for input and one for output. Please refer to the tutorial geting started with images.

```
let source = { cv.imread('first'), cv.imread('second') };
```

Then, we use HTML DOM Input Range Objec to implement the trackbar, which is shown as below.

> `<input>` elements with type="range" are not supported in internet explorer 9 and earlier versions.

You can create an `<input>` element with type="range" with the `document.createElement()` method:

```
let x = document.createElement('INPUT');
x.setAttribute('type', 'range');
```

You can access an `<input>` element with type="range" with getElementById():

```
let x = document.getElementById('myRange');
```

As a trackbar, the range element need a trackbar name, the default vlue, minimum value, maximum value, step and the callback function which is executed every time trackbar value cahnges. The callback function always has a default argument, which is the trackbar position. Additionally a text element to display the trackbar value is fine. In our case, we can create the trackbar as below:

```
Weight: <input type="range" id="trackbar" value="50" min="0" max="100" step="1" oninput="callback()">
<input type="text" id ="weightValue" size = 3 value=50 />
```

Finally, we can use the trackbar value in the callback function, blend the two images, and display the result.

```
let weight = document.getElementById('weight');
let trackbar = document.getElementById('trackbar');
weight.setAttribute('value', trackbar.value);
let alpha = trackbar.value/trackbar.max;
let beta = (1.0 - alpha);
let sources = [ im.read('first'), im.read('second') ];
let destination = new cv.Mat();
cv.addWeighted(source[0], alpha, source[2], beta, 0.0, destination, -1);
cv.imshow('output', destination);
destination.delete();
source[0].delete();
source[1].delete();
```
-->

---

DOMException: "Index or size is negative or greater than the allowed amount"

비디오의 크기가 가변적일 경우 그와 알맞은 매트(Mat)를 생성하기 위해서 보정이 필요하다.

__VIDEO__

<video id="video" width="400" style="border: 1px solid #000000;" autoplay playsinline></video>

__OUTPUT__

<canvas id="output" width="400" style="border: 1px solid #000000;"></canvas>

<script type="text/javascript">
  // put variables in global scope to make them available to the browser console.
  const constrains = window.constrains = {video: true, audio: false};



  async function init(e) {
    try {
      const stream = await navigator.mediaDevices.getUserMedia(constrains);
      const video = document.getElementById('video');
      const tracks = stream.getVideoTracks();
      // make variable available to browser console
      window.stream = stream;
      video.srcObject = stream;
      e.target.disabled = true;

      document.getElementById('output').width = video.width;

      video.height = parseInt(stream.getVideoTracks()[0].getSettings().height * (video.width / stream.getVideoTracks()[0].getSettings().width));
      document.getElementById('output').height = video.height;

      // document.getElementById('output').height =
      // console.log(parseInt(stream.getVideoTracks()[0].getSettings().height * (video.width / stream.getVideoTracks()[0].getSettings().width)));
      let streaming= true;

      console.log(video.height);
      console.log(video.width);

      let source = new cv.Mat(video.height, video.width, cv.CV_8UC4);
      let destination = new cv.Mat(video.height, video.width, cv.CV_8UC1);
      let capture = new cv.VideoCapture(video);

      console.log(video);

      console.log(stream.getVideoTracks()[0].getSettings().deviceId);
      console.log(stream.getVideoTracks()[0].getSettings().frameRate);
      console.log(stream.getVideoTracks()[0].getSettings().height);
      console.log(stream.getVideoTracks()[0].getSettings().width);
      console.log(stream.getVideoTracks()[0].getSettings().frameRate);

      const fps = 30;
      function process() {
        console.log(1);
        try {
          if(!streaming) {
            // clean and stop
            source.delete();
            destination.delete();
            return;
          }
          let begin = Date.now();
          // start
          capture.read(source);
          cv.cvtColor(source, destination, cv.COLOR_RGBA2GRAY);
          cv.imshow('output', destination);
          setTimeout(process, 1000/fps + (Date.now() - begin));
        } catch(e) {
          console.log(e);
        }
      }
      process();
    } catch(e) {
      console.log(e);
    }
  }
</script>

<button id="start">START</button>

<script>
  let start = document.getElementById('start');
  start.addEventListener('click', (event) => init(event) );
</script>

<button>STOP</button>

> - [webrtc - getting started](https://webrtc.org/start/)
> - [getting started with webrtc](https://www.html5rocks.com/en/tutorials/webrtc/basics/)
> - [Get media details(resolution and frame rate) from MediaStream object](https://stackoverflow.com/questions/26076259/get-media-detailsresolution-and-frame-rate-from-mediastream-object)



<!--

----

<a name="iticworld-getting-started-with-video"></a>

----

<a name="opencv-getting-started-with-videos"></a>
## GETTING STARTED WITH VIDEOS

> https://docs.opencv.org/4.2.0/dd/d00/tutorial_js_video_display.html

### GOAL

Learn to capture video from a camera and display it.

### CAPTURE VIDEO FROM CAMERA

Often, we have to capture live stream with a camera. In OpenCV.js, we use WebRTC and HTML canvas element to implement this. Let's capture a video from the camera (built-in or a usb), convert it into grayscale video and display it.

To capture a video, you need to add some HTML elements to the web page:

- a `<video>` to display video from camera directly
- a `<canvas>` to transfer video to canvas ImageData frame by frame
- another `<canvas>` to display the video OpenCV.js gets

First, we use WebRTC navigator.mediaDevices.getUserMedia to get the media stream.

```
// video is the id pf video tag
let video = document.getElementById("input");
navigator.mediaDevices.getUserMedia({video: true, audio: false})
  .then(function(stream) {
    video.srcObject = stream;
    video.play();
  })
  .catch(function(err){
    console.log("an error occurred! " + err);
  });
```

> This function is unnecessary when you capture video from a video file. But notice that HTML video element only supports video formats of Ogg(Theora), WebM(VP8/VP9) or MP4(H.264).

### PLAYING VIDEO

Now, the browser gets the camera stream. Then, we use CanvasRenderingContext2D.drawImage() method of the Canvas 2D API to draw video onto the canvas. Finally, we can use the method in getting started with images to read and display image in canvas. For playing video, cv.imshow() should be executed every delay milliseconds. We recommended setTimeout() method. And if the video is 30fps, the delay milliseconds should be (1000/30 - processing_time).

```
// frame is the id of <canvas>
let frame = document.getElementById("frame");
let context = frame.getContext('2d');
let source = new cv.Mat(height, width, cv.CV_8UC4);
let destination = new cv.Mat(height, width, cv.CV_8UC1);

const fps = 30;
function process(){
  let begin = Date.now();
  context.drawImage(video, 0, 0, width, height);
  source.data.set(context.getImageData(0, 0, width, height).data);
  cv.cvtColor(source, destination, cv.COLOR_RGBA2GRAY);
  cv.imshow("output", destination);
  // schedule
  let delay = 1000/fps - (Date.now() - begin;
  setTimeout(process, delay);
}

setTimeout(process, 0);
```

OpenCV.js implements cv.VideoCapture(source) using the above method. You need not to add the hidden canvas element manually.

----

```
cv.VideoCapture(source): cv.VideoCapture
```

__PARAMETER__

| source | the video id or element |

__RETURN__

cv.VideoCapture instance

----

We use read(image) to get one frame of the video. For performance reasons, the image should be constructed with cv.CV_8UC4 type and same size as the video.

----

```
read(image)
```

__PARAMETER__

| image | image with cv.CV_8UC4 type and same size as the video |

----

The above code of playing video could be simplified as below:

```
let source = new cv.Mat(height, width, cv.CV_8UC4);
let destination = new cv.Mat(height, width, cv.CV_8UC1);
let capture = new cv.VideoCapture(video);

const fps = 30;
function process() {
  let begin = Date.now();
  capture.read(source);
  cv.cvtColor(source, destination, cv.COLOR_RGBA2GRAY);
  cv.imshow("output", destination);
  setTimeout(1000/fps - (Date.now() - begin));
}

setTimeout(process, 0);
```

> Remember to delete source and destination when stop.

-->



| criterion    | 기준, 평가, 심사, 조건, 자격 |
| discriminant | 판별 수단, 판별식 |
| discriminant criterion | 판별기준 |
| resultant | 결과로서 생기는, 결과, 합성적인 |
| adequate | 적당한, 충분한, 부족하지않은 |
| in this regard | 그런점에서, 이에 대해, 이와 관련하여, 이런 면에서, 이런 관점에서 |
| regard | 관련되다. 간주하다. 여기다. 보다. 생각하다. |
| tedious | 지루한, 장황한 |
| meager | 빈약한, 메마른, 결핍한 |
| derive | 나오다. 기인하다 얻다. |
| standpoint | 관점, 입장, 견지 |
| imply | 암시하다. 함축하다. |
| correspondence | 대응, 일치, 시선, 보고, 통신문 |
| confine | 국한하다. 가두다. 제한하다. 꽉 막힌, 휠체어를 타는 |
| elementary | 초등의, 초등학교의, 기본의 |
| suffice | 충분하다. 말해두다 |
| dichotomize | 양분하다. 분기하다. |
| suppose | 생각하다. 해야만 한다. 가정하다. 예쩡이다. 기대하다 |
| denote | ...의 외연을 나타내다. ...의 명칭이다. 표시하다. |
| occurrence | 발생, 양상, 출현, 사건, 일어난 일 |
| motivated | 동기부여, 의욕, 목적의식, 자극하다. 주도 |
| conjecture | 추측하다. 문제, 해독 |
| conversely | 거꾸로, 역관계에 있어서, 반대로 |
| equivalently | 동등하게, 맞먹게 |
| sought | seek 의 과거, 과거분사형 |
| bimodality| 이중모드 |
| significant | 중요한, 상당한, 의미심장한, 의미있는, 중대한 |
| invariant | 불변의, 불변식, 변함없는 |
| dilatation | 팽창, 확장한 것, 부연 |
| attainable | 달성할 수 있는, 이를 수 있는, 도달할 수 있는 |
| unity | 통합, 단결, 협조, 개체 |
| credible | 신용할 수 있는, 확실한, 믿을 수 있는 |
| cytoplasm | 세포질 |
| nucleus | 핵, 단위, 미립자 |
| theoretically | 이론적으로, 이론상 |
| satisfactory | 만족스러운 |
| practical | 실용적인, 실제적인, 실질상의, 현실적인 |
| attest | 증명하다. 입증하다. 증언하다 |
| unimodal | 봉우리가 하나인, 단봉의 |
| rigorous | 엄격한, 혹독한, 철저한, 엄밀한, 정밀한 |
| desirable | 바람직한 |
| virtue | 미덕, 덕목, 군자. 덕행, 장점 |
| foregoing | 앞서 말한, 앞서말한 것, 앞의 |
| discriminative | 특이한, 식별하는, 특징적인 |

<!--
[calculus](#calculus)<br />

----

<a name="calculus"></a>

## CALCULUS

__FUNCTION__

y = x<sup>2</sup> - x + 2

__OUTPUT__

<div id="example-calculus-output">&nbsp;</div>

<script>
  function example1(x)
  {
    return x * x - x + 2;
  }
  let input = [
    1.0,
    1.5,
    1.8,
    1.9,
    1.95,
    1.99,
    1.995,
    1.999,
    3.0,
    2.5,
    2.2,
    2.1,
    2.05,
    2.01,
    2.005,
    2.001
  ];
  function runExample1(){
    var o = document.getElementById('example-calculus-output');
    while(o.firstChild) {
      o.removeChild(o.firstChild);
    }
    let output = input.forEach(x => {
      let y = example1(x)
      let text = document.createTextNode('[' + x + ',' + y + ']');
      let div = document.createElement('div');
      div.appendChild(text);
      o.appendChild(div);
    });
  }

</script>

<button onclick="runExample1()">RUN</button>

| 1.0   | 2.000000 |
| 1.5   | 2.750000 |
| 1.8   | 3.440000 |
| 1.9   | 3.710000 |
| 1.95  | 3.852500 |
| 1.99  | 3.970100 |
| 1.995 | 3.985025 |
| 1.999 | 3.997001 |
| 3.0   | 8.000000 |
| 2.5   | 5.750000 |
| 2.2   | 4.640000 |
| 2.1   | 4.310000 |
| 2.05  | 4.152500 |
| 2.01  | 4.030100 |
| 2.005 | 4.015025 |
| 2.001 | 4.003001 |

<div id="example-calculus-chart" style="width: 300px; height: 600px"></div>


<script type="text/javascript">
  google.charts.load('current', {'packages':['corechart']});
  google.charts.setOnLoadCallback(drawChart);

  function example_func(x){ return x * x - x + 2; }

  let output = [];
  for(let i = -1; i < 4; i = i + 0.2) {
    output.push([i, example_func(i)]);
  }
  output.unshift(['x-value', 'y-value']);

  console.log(output);

  function drawChart() {
    var data = google.visualization.arrayToDataTable(output);

    var options = {
      title: 'f(x) = x * x - x + 2',
      curveType: 'function',
      legend: { position: 'bottom' }
    };

    var chart = new google.visualization.LineChart(document.getElementById('example-calculus-chart'));

    chart.draw(data, options);
  }
</script>

---

__에제__

<div id="example2-output">&nbsp;</div>

<script>
  function example2()
  {

  }
  function example2_func(x)
  {
    return (x - 1) / (x * x - 1);
  }
</script>

__예제__

<div id="example-calculus2-output">&nbsp;</div>

<script>
  function example_calculus2_func(x)
  {
    return (Math.sqrt(x * x + 9) - 3) / (x * x);
  }
  function example_calculate2_run()
  {
    let input = [-0.01, -0.5, -0.1, 0.1, 0.5, 0.01];
    let o = document.getElementById('example-calculus2-output');
    while(o.firstChild){
      o.removeChild(o.firstChild);
    }
    let out = '[';
    input.forEach((x, index) => {
      let y = example_calculus2_func(x);
      out += '[' + x + ',' + y + ']';
      if(index + 1 !== input.length) {
        out += ',';
      }
    });
    out += ']';
    let text = document.createTextNode(out);
    o.appendChild(text);
  }
  example_calculate2_run();
</script>

| -0.01 | 0.16666620370475727 |
| -0.5  | 0.16552506059643868 |
| 0.1   | 0.16662039607266974 |
| 0.1   | 0.16662039607266974 |
| 0.5   | 0.16552506059643868 |
| 0.01  | 0.16666620370475727 |

<div id="example-calculus3-output">&nbsp;</div>

<script>
  function example_calculate2_run()
  {
    let input = [-0.0005, -0.0001, -0.00005, 0.00005, 0.0001, 0.0005];
    let o = document.getElementById('example-calculus3-output');
    while(o.firstChild){
      o.removeChild(o.firstChild);
    }
    let out = '[';
    input.forEach((x, index) => {
      let y = example_calculus2_func(x);
      out += '[' + x + ',' + y + ']';
      if(index + 1 !== input.length) {
        out += ',';
      }
    });
    out += ']';
    let text = document.createTextNode(out);
    o.appendChild(text);
  }
  example_calculate2_run();
</script>


| -0.0005  | 0.16666666446951695 |
| -0.0001  | 0.1666666804567285  |
| -0.00005 | 0.1666666804567285  |
| 0.00005  | 0.1666666804567285  |
| 0.0001   | 0.1666666804567285  |
| 0.0005   | 0.16666666446951695 |

-->
