---
layout: post
title: "2020년 01월 06월 개발로그"
---

[OPENCV JAVASCRIPT - CHANGING COLORSPACES](#opencv-js-change-colorspaces)<br />
[OPENCV JS - GEOMETRIC TRANSFORMATIONS OF IMAGES](#opencv-js-geometric-transformations-of-images)

__PERSPECTIVE TRANSFORMATION__

<img id="perspective-transformation-input" src="/assets/images/first.jpg">

<canvas id="perspective-transformation-output"></canvas>

<script>
  function perspectiveTransformRun(){
    let source = cv.imread('perspective-transformation-input');
    let destination = new cv.Mat();
    let dsize = new cv.Size(source.rows, source.cols);
    let src = cv.matFromArray(4, 1, cv.CV_32FC2, [10, 30, 88, 10, 28, 97, 99, 90]);
    let dst = cv.matFromArray(4, 1, cv.CV_32FC2, [0, 0, 50, 0, 0, 50, 50, 50]);

    try {
      let m = cv.getPerspectiveTransform(src, dst);
      cv.warpPerspective(source, destination, m, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());
    } catch(e) {
      console.log(e);
    }

    cv.imshow('perspective-transformation-output', destination);
    source.delete();
    destination.delete();
    m.delete();
    src.delete();
    dst.delete();
  }
  dispatch(perspectiveTransformRun);
</script>

For perspective transformation, you need a 3 x 3 tranformation matrix. Straight lines will remain straight even after the tranformation. To find this transformation matrix, you need 4 points on the input image and corresponding points on the output image. Among these 4 points, 3 of them should not be collinear. Then transformation matrix can be found by the function cv.getPerspectiveTransform. Then apply cv.warpPerspective with this 3x3 transformation matrix.

```
cv.warpPerspective(source, destination, dsize, flags = cv.INTER_LINEAR, borderMode = cv.BORDER_CONSTANT, borderValue = new cv.Scalar())
```

| source      | input image |
| destination | output image that has the size dsize and the same type as source. |
| mat         | 3 x 3 transformation matrix (cv.CV_64FC1 type) |
| dsize       | size of the output image.                      |
| flags       | combination of interpolation methods (cv.INTER_LINEAR or cv.INTER_NEAREST) and the optional flag WARP_INVERSE_MAP, that sets M as the inverse transformation |
| borderMode  | pixel extrapolation method (cv.BORDER_CONSTANT or cv.BORDER_REPLICATE) |
| borderValue | value used in case of a constant border; by default, it is 0 |

cv.getPerspectiveTransform(source, destination)

| source | coordinate of quadrangle vertices in the source images. |
| destination | coordinate of the corresponding quadrange vertices in the destination image. |

__AFFINE TRANSFORMATION__


<img id="affine-transformation-input" src="/assets/images/first.jpg">

<canvas id="affine-transformation-output"></canvas>

<script>
  function runGetAffineTransformation() {
    let source = cv.imread('affine-transformation-input');
    let destination = new cv.Mat();
    let src = cv.matFromArray(3, 1, cv.CV_32FC2, [  0,   0,   0,   1,   1,   0]);
    let dst = cv.matFromArray(3, 1, cv.CV_32FC2, [0.6, 0.2, 0.1, 1.3, 1.5, 0.3]);
    let dsize = new cv.Size(source.rows, destination.cols);
    let m = cv.getAffineTransform(src, dst);
    cv.warpAffine(source, destination, m, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());
    cv.imshow('affine-transformation-output', destination);
    source.delete();
    destination.delete();
    m.delete();
    src.delete();
    dst.delete();
  }
  dispatch(runGetAffineTransformation);
</script>

In affine transformation, all parallel lines in the original image will still be paralle in the output image. To find the transformation matrix, we need three points from input image and their corresponding locations in output image. Then cv.getAffineTransform will create a 2x3 matrix which is to be passed to cv.warpAffine.

```
cv.getAffineTransform(source, destination)
```

| source | three points([3, 1] size and cv.CV_32FC2 type) from input imag.
| destination | three corresponding points [3, 1] size and cv.CV_32FC2 type in output image.

__ROTATION__

<img id="rotation-input" src="/assets/images/first.jpg">

<canvas id="rotation-output"></canvas>

<script>
  function rotationRun() {
    let source = cv.imread('rotation-input');
    let destination = new cv.Mat();
    let dsize = new cv.Size(source.rows, destination.cols);
    let center = new cv.Point(source.cols/2, source.rows/2);
    let m = cv.getRotationMatrix2D(center, 45, 1);
    cv.warpAffine(source, destination, m, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());
    cv.imshow('rotation-output', destination);
    source.delete();
    destination.delete();
    m.delete();
  }
  dispatch(rotationRun);
</script>

----

Rotation of an image for an angle <math><semantics><mi>θ</mi></semantics></math> is achieved by the transformation matrix of the form

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mi>M</mi>
   <mo stretchy="false">=</mo>
   <mrow>
    <mo fence="true" stretchy="true">|</mo>
    <mrow>
     <mtable>
      <mtr>
       <mtd>
        <mrow>
         <mi>cos</mi>
         <mi>θ</mi>
        </mrow>
       </mtd>
       <mtd>
        <mrow>
         <mrow>
          <mo stretchy="false">−</mo>
          <mi>sin</mi>
         </mrow>
         <mi>θ</mi>
        </mrow>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mrow>
         <mi>sin</mi>
         <mi>θ</mi>
        </mrow>
       </mtd>
       <mtd>
        <mrow>
         <mi>cos</mi>
         <mi>θ</mi>
        </mrow>
       </mtd>
      </mtr>
     </mtable>
    </mrow>
    <mo fence="true" stretchy="true">|</mo>
   </mrow>
  </mrow>
 </semantics>
</math>

But OpenCV provides scaled rotation with adjustable center of rotation so that you can rotate at any location you prefer. Modified transformation matrix is given by

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mi>M</mi>
   <mo stretchy="false">=</mo>
   <mrow>
    <mo fence="true" stretchy="true">|</mo>
    <mrow>
     <mtable>
      <mtr>
       <mtd>
        <mi>α</mi>
       </mtd>
       <mtd>
        <mi>β</mi>
       </mtd>
       <mtd>
        <mrow>
         <mrow>
          <mrow>
           <mo fence="true" stretchy="false">(</mo>
           <mrow>
            <mrow>
             <mn>1</mn>
             <mo stretchy="false">−</mo>
             <mi>α</mi>
            </mrow>
           </mrow>
           <mo fence="true" stretchy="false">)</mo>
          </mrow>
          <mo stretchy="false">⋅</mo>
          <mi mathvariant="italic">center</mi>
         </mrow>
         <mi>.</mi>
         <mrow>
          <mi>x</mi>
          <mo stretchy="false">−</mo>
          <mrow>
           <mi>β</mi>
           <mo stretchy="false">⋅</mo>
           <mi mathvariant="italic">center</mi>
          </mrow>
         </mrow>
         <mi>.</mi>
         <mi>y</mi>
        </mrow>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mrow>
         <mo stretchy="false">−</mo>
         <mi>β</mi>
        </mrow>
       </mtd>
       <mtd>
        <mi>α</mi>
       </mtd>
       <mtd>
        <mrow>
         <mrow>
          <mi>β</mi>
          <mo stretchy="false">⋅</mo>
          <mi mathvariant="italic">center</mi>
         </mrow>
         <mi>.</mi>
         <mrow>
          <mi>x</mi>
          <mo stretchy="false">−</mo>
          <mrow>
           <mrow>
            <mo fence="true" stretchy="false">(</mo>
            <mrow>
             <mrow>
              <mn>1</mn>
              <mo stretchy="false">−</mo>
              <mi>α</mi>
             </mrow>
            </mrow>
            <mo fence="true" stretchy="false">)</mo>
           </mrow>
           <mo stretchy="false">⋅</mo>
           <mi mathvariant="italic">center</mi>
          </mrow>
         </mrow>
         <mi>.</mi>
         <mi>y</mi>
        </mrow>
       </mtd>
      </mtr>
     </mtable>
    </mrow>
    <mo fence="true" stretchy="true">|</mo>
   </mrow>
  </mrow>
  <annotation encoding="StarMath 5.0">M = left lline {
matrix {
  %alpha # %beta # { (1-%alpha) cdot center.x - %beta cdot center.y} ##
  -%beta # %alpha # { %beta cdot center.x - (1-%alpha) cdot center.y}
}
} right rline</annotation>
 </semantics>
</math>

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mrow>
    <mi>α</mi>
    <mo stretchy="false">=</mo>
    <mrow>
     <mi mathvariant="italic">scale</mi>
     <mo stretchy="false">⋅</mo>
     <mi>cos</mi>
    </mrow>
   </mrow>
   <mi>θ</mi>
  </mrow>
  <annotation encoding="StarMath 5.0">%alpha = scale cdot cos %theta</annotation>
 </semantics>
</math>

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mrow>
    <mi>β</mi>
    <mo stretchy="false">=</mo>
    <mrow>
     <mi mathvariant="italic">scale</mi>
     <mo stretchy="false">⋅</mo>
     <mi>sin</mi>
    </mrow>
   </mrow>
   <mi>θ</mi>
  </mrow>
  <annotation encoding="StarMath 5.0">%beta = scale cdot sin %theta</annotation>
 </semantics>
</math>

```
cv.getRotatioMatrix2D(center, angle, scale)
```

| center | center of the rotation in the source image |
| angle  | rotation angle in degress. Positive values mean counter-clockwise (the coordinate origin is assumed to be the top-left cornet). |
| scale  | isotropic scale factor. |




<a name="opencv-js-geometric-transformations-of-images"></a>
## [OPENCV JS - GEOMETRIC TRANSFORMATIONS OF IMAGES]

<img width="100" id="transformation-input" src="/assets/images/first.jpg">

<canvas width="100" id="transformation-output"></canvas>

<script type="text/javascript">
  function TransformationRun() {
    let source = cv.imread('transformation-input');
    let destination = new cv.Mat();
    let M = cv.matFromArray(2, 3, cv.CV_64FC1, [1, 0, 10, 0, 1, 20]);
    let dsize = new cv.Size(source.rows, source.cols);
    cv.warpAffine(source, destination, M, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());
    console.log(destination.rows);
    console.log(destination.cols);
    cv.imshow('transformation-output', destination);
    source.delete();
    destination.delete();
    M.delete();
  }
  dispatch(TransformationRun);
</script>

### GOAL

Learn how to apply different geometric transformation to image like translation, rotation, affine transformation etc.

### TRANSFORMATIONS

__TRANSLATION__

Translation is the shifting of object's location. If you know the shift in (x, y) direction, let it be (t<sub>x</sub>, t<sub>y</sub>), you can create the transformation matrix M as follows:

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mi>M</mi>
   <mo stretchy="false">=</mo>
   <mrow>
    <mo fence="true" stretchy="true">|</mo>
    <mrow>
     <mtable>
      <mtr>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <mn>0</mn>
       </mtd>
       <mtd>
        <msub>
         <mi>t</mi>
         <mi>x</mi>
        </msub>
       </mtd>
      </mtr>
      <mtr>
       <mtd>
        <mn>0</mn>
       </mtd>
       <mtd>
        <mn>1</mn>
       </mtd>
       <mtd>
        <msub>
         <mi>t</mi>
         <mi>y</mi>
        </msub>
       </mtd>
      </mtr>
     </mtable>
    </mrow>
    <mo fence="true" stretchy="true">|</mo>
   </mrow>
  </mrow>
  <annotation encoding="StarMath 5.0">M = left lline {
matrix {
  1 # 0 # t_x ##
  0 # 1 # t_y
}
} right rline</annotation>
 </semantics>
</math>

```
cv.warpAffine(source, destination, M, dsize, flags = cv.INTER_LINEAR, borderMode = cv.BORDER_CONSTANT, borderValue = new cv.Scalar())
```

| source | input image |
| destination | output image that has the dsize and the same type as source |
| m           | 2 x 3 transfomration matrix |
| dsize       | size of the output image |
| flags       | combination of interploation methods and the optional flag WARP_INVERSE_MAP that means that matrix is the inverse transformation |
| borderMode  | pixel extrapolation method; the borderMode = BORDER_TRANSPARENT, it means that the pixels in the destination image corresponding to the "outliers" in the source image are not modified by the function. |
| borderValue | value used in case of a constant border; byt default, it is 0 |

__SCALING__

Scaling is just resize of the image. OpenCV comes with a function `cv.resize()` for this purpose. The size of the image can be specified manually, or you can specify the scaling factor. Different interpolation methods are used. Preferable interpolation methods are cv.INTER_AREA for shrinking and cv.INTER_CUBIC (slow) & cv.INTER_LINEAR for zooming.

```
cv.resize(source, destination, dsize, fx = 0, fy = 0, interpolation = cv.INTER_LINEAR)
```

| source      | input image |
| destination | output image; it has the size dsize (when it is non-zero) or the size computed from source.size(), fx, and fy; the type of destination is the same as of source. |
| dsize       | output image size; if it equals zero, it is computed as dsize = size(round(fx * source.cols), round(fy * source.rows)) either dsize of both fx and fy must be non-zero |
| fx          | scale factor along the horizontal axis; when it equals 0, it is computed as (double) dsize.width/source/cols |
| fy          | scale factor along the vertical axis; when it equals 0, it is computed as (double)dsize.height/source.rows |
| interplation | interpolation method |

| interpolation | 삽입 |

<img id="opencv-js-resize-input" src="/assets/images/first.jpg">

<canvas width="100" height="100" id="opencv-js-resize-output"></canvas>

<script type="text/javascript">
  function opencvJsResizeRun() {
    let source = cv.imread('opencv-js-resize-input');
    let destination = new cv.Mat();
    let dsize = new cv.Size(100, 100);
    cv.resize(source, destination, dsize, 0, 0, cv.INTER_AREA);
    cv.imshow('opencv-js-resize-output', destination);
    source.delete();
    destination.delete();
  }
  dispatch(opencvJsResizeRun);
</script>

<a name="opencv-js-change-colorspaces"></a>
## [OPENCV JS - CHANGE COLORSPACES]

### GOAL

- In this tutorial, you will learn how to convert images from one color space to another, like RGB -> GRAY, RGB -> HSV etc.
- You will learn following functions: cv.cvtColor(), cv.inRange() etc.

### CONVERT COLOR

There are more than 150 color space conversion methods available in OpenCV. But we will look into the most widely used one: RGB and Gray.

```
cv.cvtColor(source, destination, code, dstCn = 0)
```

| source | input image |
| destination | output image of the same size and depth as source |
| code | color space conversion code |
| dstCn | number of channels in the destination image; if the parameter is 0, the number of the channels is derived automatically from source and code. |

<img id="opencv-js-change-colorspaces-input" src="/assets/images/first.jpg" width="100">

<canvas id="opencv-js-change-colorspaces-output"></canvas>

<script type="text/javascript">
  function opencvChangeColorspacesInputRun() {
    let o = document.getElementById('opencv-js-change-colorspaces-input');
    document.getElementById('opencv-js-change-colorspaces-output').width = o.clientWidth;
    document.getElementById('opencv-js-change-colorspaces-output').height = o.clientHeight;
    let source = cv.imread('opencv-js-change-colorspaces-input');
    let destination = new cv.Mat();
    cv.cvtColor(source, destination, cv.COLOR_RGBA2GRAY, 0);
    cv.imshow('opencv-js-change-colorspaces-output', destination);
    source.delete();
    destination.delete();
  }
  dispatch(opencvChangeColorspacesInputRun);
</script>

### IN RANGE

Check if array elements lie between the elements of two other arrays.

```
cv.inRange(source, lowerb, upperb, dst)
```

| source | first input image |
| lowerb | inclusive lower boundary Mat of the same size as source |
| upperb | inclusive upper boundary Mat of the same size as source |
| dst    | output image of the same size as source and cv.CV_8U type |

<img id="opencv-js-change-colorspaces-inrange-input" src="/assets/images/first.jpg" width="100">

<canvas id="opencv-js-change-colorspaces-inrange-output"></canvas>

<script type="text/javascript">
  function opencvJsChangeColorspacesInRangeRun() {
    let o = document.getElementById('opencv-js-change-colorspaces-inrange-input');
    document.getElementById('opencv-js-change-colorspaces-inrange-output').width = o.clientWidth;
    document.getElementById('opencv-js-change-colorspaces-inrange-output').height = o.clientHeight;
    let source = cv.imread('opencv-js-change-colorspaces-inrange-input');
    let destination = new cv.Mat();
    let low = new cv.Mat(source.rows, source.cols, source.type(), [0, 0, 0, 0]);
    let high = new cv.Mat(source.rows, source.cols, source.type(), [150, 150, 150, 255]);
    cv.inRange(source, low, high, destination);
    cv.imshow('opencv-js-change-colorspaces-inrange-output', destination);
    source.delete();
    destination.delete();
    low.delete();
    high.delete();
  }
  dispatch(opencvJsChangeColorspacesInRangeRun);
</script>

<!--
<a name="mathematics"></a>
## MATHEMATICS

__정의__ <math><mi>a</mi></math>와 같지는 않지만 <math><mi>a</mi></math>에 충분히 가까운 <math><mi>x</mi></math>를 잡으면 <math><mi>L</mi></math>에 얼마든지 가까운 <math><semantics><mrow><mi>f</mi><mrow><mo fence="true" stretchy="false">(</mo><mrow><mi>x</mi></mrow><mo fence="true" stretchy="false">)</mo></mrow></mrow></semantics></math> 값을 얻을 수 있을 때

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
 <semantics>
  <mrow>
   <mrow>
    <munder>
     <mi>lim</mi>
     <mrow>
      <mi>x</mi>
      <mo stretchy="false">→</mo>
      <mi>a</mi>
     </mrow>
    </munder>
    <mrow>
     <mi>f</mi>
     <mrow>
      <mo fence="true" stretchy="false">(</mo>
      <mrow>
       <mi>x</mi>
      </mrow>
      <mo fence="true" stretchy="false">)</mo>
     </mrow>
    </mrow>
   </mrow>
   <mo stretchy="false">=</mo>
   <mi>L</mi>
  </mrow>
  <annotation encoding="StarMath 5.0">lim from { x -&gt; a } { f(x) } = L</annotation>
 </semantics>
</math>

로 나타내고 "<math><mi>x</mi></math>가 <math><mi>a</mi></math>에 접근할 때 <math><semantics><mrow><mi>f</mi><mrow><mo fence="true" stretchy="false">(</mo><mrow><mi>x</mi></mrow><mo fence="true" stretchy="false">)</mo></mrow></mrow></semantics></math>의 극한은 <math><mi>L</mi></math>이다."라고 말한다.
-->
